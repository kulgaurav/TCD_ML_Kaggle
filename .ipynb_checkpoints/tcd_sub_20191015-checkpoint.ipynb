{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(data):\n",
    "\n",
    "    print(\"\\nBeginning Cleanup...\")\n",
    "    #Imputing data    \n",
    "    data[\"Age\"].fillna(round(data[\"Age\"].mean()),inplace=True)                              #replacing missing values for integer columns\n",
    "    data[\"Year of Record\"].fillna(data[\"Year of Record\"].mode()[0],inplace=True)    \n",
    "    data[\"Size of City\"].fillna(round(data[\"Size of City\"].mean()),inplace=True)    \n",
    "    \n",
    "    data[\"Gender\"].fillna(data[\"Gender\"].mode()[0],inplace=True)                            #replacing missing values for string columns\n",
    "    data[\"Country\"].fillna(data[\"Country\"].mode()[0],inplace=True)\n",
    "    data[\"University Degree\"].fillna(data[\"University Degree\"].mode()[0],inplace=True)\n",
    "    data[\"Hair Color\"].fillna(data[\"Hair Color\"].mode()[0],inplace=True)    \n",
    "    data[['Profession']]=data[['Profession']].fillna(value='9999')                          #replacing profession missing values with 9999\n",
    "    \n",
    "    #data[\"Work Experience in Current Job [years]\"].fillna(data[\"Work Experience in Current Job [years]\"].mean(),inplace=True) \n",
    "    #data['Work Experience in Current Job [years]']=data['Work Experience in Current Job [years]'].astype(str)\n",
    "    data['Housing Situation']=data['Housing Situation'].astype(str)\n",
    "    data['Work Experience in Current Job [years]'].fillna(round(data['Work Experience in Current Job [years]'].mean()),inplace=True)\n",
    "    data['Housing Situation']=data['Housing Situation'].replace('0','zero')\n",
    "    data['Yearly Income in addition to Salary (e.g. Rental Income)'] = data['Yearly Income in addition to Salary (e.g. Rental Income)'].str.replace(r' EUR$', '')\n",
    "    data['Satisfation with employer'].fillna(data['Satisfation with employer'].mode()[0],inplace=True)\n",
    "    data['Yearly Income in addition to Salary (e.g. Rental Income)']=data['Yearly Income in addition to Salary (e.g. Rental Income)'].astype(float)\n",
    "    print(\"\\nCleanup finished...\")    \n",
    "    return data\n",
    "\n",
    "def frequency_time_blocking(data,categoricals,continuous,normalize=True):\n",
    "    for i,cat in enumerate(categoricals):\n",
    "        val_dict = data[cat].value_counts(dropna=False, normalize=normalize).to_dict()\n",
    "        nm = cat + '_FF'\n",
    "        data[nm] = data[cat].map(val_dict).astype('float32')\n",
    "        for j,con in enumerate(continuous):\n",
    "            new_col = cat +'_'+ con\n",
    "            data[new_col] = data[cat].astype(str)+'_'+data[con].astype(str)\n",
    "            temp_df = data[new_col]\n",
    "            fq_encode = temp_df.value_counts(normalize=True).to_dict()\n",
    "            data[new_col] = data[new_col].map(fq_encode)\n",
    "            data[new_col] = data[new_col]/data[cat+'_FF']\n",
    "    return data\n",
    "\n",
    "def removeRows(data):\n",
    "    \n",
    "    print('Removing outliers from Size of City')\n",
    "    outlierCity = detect_outlier(data['Size of City'])                                     \n",
    "    data=data[~data[\"Size of City\"].isin(outlierCity)]\n",
    "    print('Outliers removed from Size of City')\n",
    "    \n",
    "    print('Removing outliers from Total Yearly Income [EUR]')\n",
    "    outlierInc = detect_outlier(data['Total Yearly Income [EUR]'])\n",
    "    data=data[~data[\"Total Yearly Income [EUR]\"].isin(outlierInc)]\n",
    "    print('Outliers removed from Total Yearly Income [EUR]')\n",
    "    \n",
    "    print('Removing outliers from Age')\n",
    "    outlierAge = detect_outlier(data['Age'])\n",
    "    data=data[~data[\"Age\"].isin(outlierAge)]\n",
    "    print('Outliers removed from Age')\n",
    "    \n",
    "    print('Removing outliers from Body Height [cm]')\n",
    "    outlierHt = detect_outlier(data['Body Height [cm]'])\n",
    "    data=data[~data[\"Body Height [cm]\"].isin(outlierHt)]\n",
    "    print('Outliers removed from Body Height [cm]')\n",
    "    \n",
    "    #outlierHS = detect_outlier(data['Housing Situation'])\n",
    "    #data=data[~data[\"Housing Situation\"].isin(outlierHS)]\n",
    "    #outlierSE = detect_outlier(data['Satisfation with employer'])\n",
    "    #data=data[~data[\"Satisfation with employer\"].isin(outlierSE)]\n",
    "    print('Removing outliers from Crime Level in the City of Employement')\n",
    "    outlierCE = detect_outlier(data['Crime Level in the City of Employement'])\n",
    "    data=data[~data[\"Crime Level in the City of Employement\"].isin(outlierCE)]\n",
    "    print('Outliers removed from Crime Level in the City of Employement')\n",
    "    \n",
    "    \n",
    "    #outlierWE = detect_outlier(data['Work Experience in Current Job [years]'])\n",
    "    #data=data[~data[\"Work Experience in Current Job [years]\"].isin(outlierWE)]    \n",
    "    #outlierWE = detect_outlier(data['Yearly Income in addition to Salary (e.g. Rental Income)'])\n",
    "    #data=data[~data[\"Yearly Income in addition to Salary (e.g. Rental Income)\"].isin(outlierWE)]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def detect_outlier(data):\n",
    "    \n",
    "    threshold=3\n",
    "    mean_1 = np.mean(data)\n",
    "    std_1 =np.std(data)\n",
    "    outliers=[]\n",
    "    for y in data:\n",
    "        z_score= (y - mean_1)/std_1 \n",
    "        if np.abs(z_score) > threshold:\n",
    "            outliers.append(y)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:\\\\Users\\\\SIDDHARTHA\\\\Dropbox\\\\Trinity Data Science\\\\ML\\\\tcd-ml-comp-201920-income-pred-group\\\\tcd-ml-1920-group-income-train.csv\")\n",
    "\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\SIDDHARTHA\\\\Dropbox\\\\Trinity Data Science\\\\ML\\\\tcd-ml-comp-201920-income-pred-group\\\\tcd-ml-1920-group-income-test.csv\")\n",
    "\n",
    "train.drop_duplicates(inplace=True)\n",
    "test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape orig:  (991709, 17)\n",
      "Removing outliers from Size of City\n",
      "Outliers removed from Size of City\n",
      "Removing outliers from Total Yearly Income [EUR]\n",
      "Outliers removed from Total Yearly Income [EUR]\n",
      "Removing outliers from Age\n",
      "Outliers removed from Age\n",
      "Removing outliers from Body Height [cm]\n",
      "Outliers removed from Body Height [cm]\n",
      "Removing outliers from Crime Level in the City of Employement\n",
      "Outliers removed from Crime Level in the City of Employement\n",
      "Train shape new:  (958423, 17)\n",
      "(1327861, 17)\n",
      "\n",
      "Beginning Cleanup...\n",
      "\n",
      "Cleanup finished...\n"
     ]
    }
   ],
   "source": [
    "print('Train shape orig: ',str(train.shape))\n",
    "train=removeRows(train)\n",
    "print('Train shape new: ',str(train.shape))\n",
    "splitter_index=train.shape[0]\n",
    "data = pd.concat([train,test],ignore_index=True)\n",
    "print(data.shape)\n",
    "data = cleanUp(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = ['Year of Record', 'Gender', 'Country',\n",
    "        'Profession', 'University Degree','Wears Glasses','Age'\n",
    "        'Hair Color','Housing Situation','Satisfation with employer']\n",
    "#,'Housing Situation','Satisfation with employer']\n",
    "cons = ['Size of City','Body Height [cm]','Crime Level in the City of Employement','Work Experience in Current Job [years]'\n",
    "        ,'Yearly Income in addition to Salary (e.g. Rental Income)']\n",
    "#,'Crime Level in the City of Employement','Work Experience in Current Job [years]','Yearly Income in addition to Salary (e.g. Rental Income)']\n",
    "\n",
    "data = frequency_time_blocking(data,cats,cons)\n",
    "\n",
    "for col in train.dtypes[train.dtypes == 'object'].index.tolist():\n",
    "    feat_le = LabelEncoder()\n",
    "    feat_le.fit(data[col].unique().astype(str))\n",
    "    data[col] = feat_le.transform(data[col].astype(str))\n",
    "\n",
    "del_col = set(['Total Yearly Income [EUR]','Instance'])\n",
    "features_col =  list(set(data) - del_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = data[features_col].iloc[:splitter_index],data[features_col].iloc[splitter_index:]\n",
    "Y_train = np.log(data['Total Yearly Income [EUR]'].iloc[:splitter_index])\n",
    "X_test_id = data['Instance'].iloc[splitter_index:]\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_train,Y_train,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's l1: 0.635086\tvalid_1's l1: 0.634495\n",
      "[2000]\ttraining's l1: 0.352945\tvalid_1's l1: 0.352668\n",
      "[3000]\ttraining's l1: 0.261987\tvalid_1's l1: 0.262202\n",
      "[4000]\ttraining's l1: 0.225478\tvalid_1's l1: 0.225975\n",
      "[5000]\ttraining's l1: 0.205993\tvalid_1's l1: 0.206647\n",
      "[6000]\ttraining's l1: 0.19462\tvalid_1's l1: 0.195416\n",
      "[7000]\ttraining's l1: 0.18717\tvalid_1's l1: 0.188037\n",
      "[8000]\ttraining's l1: 0.181857\tvalid_1's l1: 0.182761\n",
      "[9000]\ttraining's l1: 0.17791\tvalid_1's l1: 0.178851\n",
      "[10000]\ttraining's l1: 0.174896\tvalid_1's l1: 0.175885\n",
      "[11000]\ttraining's l1: 0.17251\tvalid_1's l1: 0.173556\n",
      "[12000]\ttraining's l1: 0.17068\tvalid_1's l1: 0.171773\n",
      "[13000]\ttraining's l1: 0.169247\tvalid_1's l1: 0.170382\n",
      "[14000]\ttraining's l1: 0.167878\tvalid_1's l1: 0.169045\n",
      "[15000]\ttraining's l1: 0.166843\tvalid_1's l1: 0.168047\n",
      "[16000]\ttraining's l1: 0.165931\tvalid_1's l1: 0.16718\n",
      "[17000]\ttraining's l1: 0.165101\tvalid_1's l1: 0.166402\n",
      "[18000]\ttraining's l1: 0.164299\tvalid_1's l1: 0.165645\n",
      "[19000]\ttraining's l1: 0.163552\tvalid_1's l1: 0.164958\n",
      "[20000]\ttraining's l1: 0.162872\tvalid_1's l1: 0.164345\n",
      "[21000]\ttraining's l1: 0.162272\tvalid_1's l1: 0.163811\n",
      "[22000]\ttraining's l1: 0.161647\tvalid_1's l1: 0.163247\n",
      "[23000]\ttraining's l1: 0.161079\tvalid_1's l1: 0.162747\n",
      "[24000]\ttraining's l1: 0.160555\tvalid_1's l1: 0.162288\n",
      "[25000]\ttraining's l1: 0.160064\tvalid_1's l1: 0.161856\n",
      "[26000]\ttraining's l1: 0.159581\tvalid_1's l1: 0.161444\n",
      "[27000]\ttraining's l1: 0.159116\tvalid_1's l1: 0.161044\n",
      "[28000]\ttraining's l1: 0.158592\tvalid_1's l1: 0.160579\n",
      "[29000]\ttraining's l1: 0.158142\tvalid_1's l1: 0.160196\n",
      "[30000]\ttraining's l1: 0.157759\tvalid_1's l1: 0.159889\n",
      "[31000]\ttraining's l1: 0.157342\tvalid_1's l1: 0.159546\n",
      "[32000]\ttraining's l1: 0.156968\tvalid_1's l1: 0.159247\n",
      "[33000]\ttraining's l1: 0.156615\tvalid_1's l1: 0.158971\n",
      "[34000]\ttraining's l1: 0.156281\tvalid_1's l1: 0.158712\n",
      "[35000]\ttraining's l1: 0.15596\tvalid_1's l1: 0.15847\n",
      "[36000]\ttraining's l1: 0.155639\tvalid_1's l1: 0.158222\n",
      "[37000]\ttraining's l1: 0.155326\tvalid_1's l1: 0.157982\n",
      "[38000]\ttraining's l1: 0.155048\tvalid_1's l1: 0.157783\n",
      "[39000]\ttraining's l1: 0.154783\tvalid_1's l1: 0.157599\n",
      "[40000]\ttraining's l1: 0.154522\tvalid_1's l1: 0.157422\n",
      "[41000]\ttraining's l1: 0.154238\tvalid_1's l1: 0.157216\n",
      "[42000]\ttraining's l1: 0.153976\tvalid_1's l1: 0.157035\n",
      "[43000]\ttraining's l1: 0.153676\tvalid_1's l1: 0.156816\n",
      "[44000]\ttraining's l1: 0.153384\tvalid_1's l1: 0.156595\n",
      "[45000]\ttraining's l1: 0.153125\tvalid_1's l1: 0.156415\n",
      "[46000]\ttraining's l1: 0.152832\tvalid_1's l1: 0.156202\n",
      "[47000]\ttraining's l1: 0.152568\tvalid_1's l1: 0.156022\n",
      "[48000]\ttraining's l1: 0.152325\tvalid_1's l1: 0.155855\n",
      "[49000]\ttraining's l1: 0.152093\tvalid_1's l1: 0.155697\n",
      "[50000]\ttraining's l1: 0.151875\tvalid_1's l1: 0.15555\n",
      "[51000]\ttraining's l1: 0.151633\tvalid_1's l1: 0.155388\n",
      "[52000]\ttraining's l1: 0.151346\tvalid_1's l1: 0.155177\n",
      "[53000]\ttraining's l1: 0.151084\tvalid_1's l1: 0.154988\n",
      "[54000]\ttraining's l1: 0.150834\tvalid_1's l1: 0.15481\n",
      "[55000]\ttraining's l1: 0.150621\tvalid_1's l1: 0.154666\n",
      "[56000]\ttraining's l1: 0.150404\tvalid_1's l1: 0.154524\n",
      "[57000]\ttraining's l1: 0.150188\tvalid_1's l1: 0.154376\n",
      "[58000]\ttraining's l1: 0.149986\tvalid_1's l1: 0.154251\n",
      "[59000]\ttraining's l1: 0.149787\tvalid_1's l1: 0.154132\n",
      "[60000]\ttraining's l1: 0.149587\tvalid_1's l1: 0.15401\n",
      "[61000]\ttraining's l1: 0.149402\tvalid_1's l1: 0.153901\n",
      "[62000]\ttraining's l1: 0.149211\tvalid_1's l1: 0.153789\n",
      "[63000]\ttraining's l1: 0.149025\tvalid_1's l1: 0.15368\n",
      "[64000]\ttraining's l1: 0.148859\tvalid_1's l1: 0.153592\n",
      "[65000]\ttraining's l1: 0.148686\tvalid_1's l1: 0.153492\n",
      "[66000]\ttraining's l1: 0.148508\tvalid_1's l1: 0.153391\n",
      "[67000]\ttraining's l1: 0.148351\tvalid_1's l1: 0.153313\n",
      "[68000]\ttraining's l1: 0.148189\tvalid_1's l1: 0.15323\n",
      "[69000]\ttraining's l1: 0.148035\tvalid_1's l1: 0.153151\n",
      "[70000]\ttraining's l1: 0.147879\tvalid_1's l1: 0.153072\n",
      "[71000]\ttraining's l1: 0.147719\tvalid_1's l1: 0.152982\n",
      "[72000]\ttraining's l1: 0.147562\tvalid_1's l1: 0.1529\n",
      "[73000]\ttraining's l1: 0.147405\tvalid_1's l1: 0.152825\n",
      "[74000]\ttraining's l1: 0.147244\tvalid_1's l1: 0.152745\n",
      "[75000]\ttraining's l1: 0.147091\tvalid_1's l1: 0.152669\n",
      "[76000]\ttraining's l1: 0.146936\tvalid_1's l1: 0.15259\n",
      "[77000]\ttraining's l1: 0.146772\tvalid_1's l1: 0.1525\n",
      "[78000]\ttraining's l1: 0.146602\tvalid_1's l1: 0.152398\n",
      "[79000]\ttraining's l1: 0.146446\tvalid_1's l1: 0.152317\n",
      "[80000]\ttraining's l1: 0.146299\tvalid_1's l1: 0.152245\n",
      "[81000]\ttraining's l1: 0.146154\tvalid_1's l1: 0.152177\n",
      "[82000]\ttraining's l1: 0.14601\tvalid_1's l1: 0.152111\n",
      "[83000]\ttraining's l1: 0.145868\tvalid_1's l1: 0.152044\n",
      "[84000]\ttraining's l1: 0.145716\tvalid_1's l1: 0.151964\n",
      "[85000]\ttraining's l1: 0.145567\tvalid_1's l1: 0.151889\n",
      "[86000]\ttraining's l1: 0.145416\tvalid_1's l1: 0.151812\n",
      "[87000]\ttraining's l1: 0.145268\tvalid_1's l1: 0.151738\n",
      "[88000]\ttraining's l1: 0.145124\tvalid_1's l1: 0.15167\n",
      "[89000]\ttraining's l1: 0.144971\tvalid_1's l1: 0.15159\n",
      "[90000]\ttraining's l1: 0.144806\tvalid_1's l1: 0.151492\n",
      "[91000]\ttraining's l1: 0.144658\tvalid_1's l1: 0.151408\n",
      "[92000]\ttraining's l1: 0.144511\tvalid_1's l1: 0.151328\n",
      "[93000]\ttraining's l1: 0.144372\tvalid_1's l1: 0.151258\n",
      "[94000]\ttraining's l1: 0.144239\tvalid_1's l1: 0.151195\n",
      "[95000]\ttraining's l1: 0.144104\tvalid_1's l1: 0.151131\n",
      "[96000]\ttraining's l1: 0.143969\tvalid_1's l1: 0.151068\n",
      "[97000]\ttraining's l1: 0.143839\tvalid_1's l1: 0.151011\n",
      "[98000]\ttraining's l1: 0.14371\tvalid_1's l1: 0.150952\n",
      "[99000]\ttraining's l1: 0.143586\tvalid_1's l1: 0.150898\n",
      "[100000]\ttraining's l1: 0.143454\tvalid_1's l1: 0.150832\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100000]\ttraining's l1: 0.143454\tvalid_1's l1: 0.150832\n"
     ]
    }
   ],
   "source": [
    "iterations=100000\n",
    "stopping_round=500\n",
    "params = {\n",
    "          'max_depth': 20,\n",
    "          'learning_rate': 0.001,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1\n",
    "         }\n",
    "trn_data = lgb.Dataset(x_train, label=y_train)\n",
    "val_data = lgb.Dataset(x_val, label=y_val)\n",
    "# test_data = lgb.Dataset(X_test)\n",
    "clf = lgb.train(params, trn_data, iterations, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=stopping_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8880.67379615857"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "pre_test_lgb = clf.predict(x_val)\n",
    "\n",
    "val_mae = mean_absolute_error(np.exp(y_val),np.exp(pre_test_lgb))\n",
    "val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_lgbdf=pd.DataFrame(pre_test_lgb)\n",
    "pre_test_lgbdf.to_csv('resultval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>958423</td>\n",
       "      <td>1</td>\n",
       "      <td>10.407050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958424</td>\n",
       "      <td>2</td>\n",
       "      <td>8.848854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958425</td>\n",
       "      <td>3</td>\n",
       "      <td>8.159023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958426</td>\n",
       "      <td>4</td>\n",
       "      <td>11.215184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958427</td>\n",
       "      <td>5</td>\n",
       "      <td>8.138199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Instance     Income\n",
       "958423         1  10.407050\n",
       "958424         2   8.848854\n",
       "958425         3   8.159023\n",
       "958426         4  11.215184\n",
       "958427         5   8.138199"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_test_lgb = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>958423</td>\n",
       "      <td>1</td>\n",
       "      <td>33092.117573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958424</td>\n",
       "      <td>2</td>\n",
       "      <td>6966.400973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958425</td>\n",
       "      <td>3</td>\n",
       "      <td>3494.771931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958426</td>\n",
       "      <td>4</td>\n",
       "      <td>74249.342350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958427</td>\n",
       "      <td>5</td>\n",
       "      <td>3422.749436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Instance        Income\n",
       "958423         1  33092.117573\n",
       "958424         2   6966.400973\n",
       "958425         3   3494.771931\n",
       "958426         4  74249.342350\n",
       "958427         5   3422.749436"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame({'Instance':X_test_id,\n",
    "                       'Income':np.exp(post_test_lgb)})\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.to_csv(\"submission2.csv\",index=False)\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = [12, 30, 1, 8, 22]\n",
    "bars2 = [28, 6, 16, 5, 10]\n",
    "bars3 = [29, 3, 24, 25, 17]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='#7f6d5f', width=barWidth, edgecolor='white', label='var1')\n",
    "plt.bar(r2, bars2, color='#557f2d', width=barWidth, edgecolor='white', label='var2')\n",
    "plt.bar(r3, bars3, color='#2d7f5e', width=barWidth, edgecolor='white', label='var3')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('group', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['A', 'B', 'C', 'D', 'E'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
