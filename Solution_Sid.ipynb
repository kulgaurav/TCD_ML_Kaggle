{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(data):\n",
    "\n",
    "    print(\"\\nBeginning Cleanup...\")\n",
    "    #Imputing data    \n",
    "    data[\"Age\"].fillna(round(data[\"Age\"].mean()),inplace=True)                              #replacing missing values for integer columns\n",
    "    data[\"Year of Record\"].fillna(data[\"Year of Record\"].mode()[0],inplace=True)    \n",
    "    data[\"Size of City\"].fillna(round(data[\"Size of City\"].mean()),inplace=True)    \n",
    "    \n",
    "    data[\"Gender\"].fillna(data[\"Gender\"].mode()[0],inplace=True)                            #replacing missing values for string columns\n",
    "    data[\"Country\"].fillna(data[\"Country\"].mode()[0],inplace=True)\n",
    "    data[\"University Degree\"].fillna(data[\"University Degree\"].mode()[0],inplace=True)\n",
    "    data[\"Hair Color\"].fillna(data[\"Hair Color\"].mode()[0],inplace=True)    \n",
    "    data[['Profession']]=data[['Profession']].fillna(value='9999')                          #replacing profession missing values with 9999\n",
    "    \n",
    "    #data[\"Work Experience in Current Job [years]\"].fillna(data[\"Work Experience in Current Job [years]\"].mean(),inplace=True) \n",
    "    #data['Work Experience in Current Job [years]']=data['Work Experience in Current Job [years]'].astype(str)\n",
    "    data['Housing Situation']=data['Housing Situation'].astype(str)\n",
    "    data['Work Experience in Current Job [years]'].fillna(round(data['Work Experience in Current Job [years]'].mean()),inplace=True)\n",
    "    data['Housing Situation']=data['Housing Situation'].replace('0','zero')\n",
    "    data['Yearly Income in addition to Salary (e.g. Rental Income)'] = data['Yearly Income in addition to Salary (e.g. Rental Income)'].str.replace(r' EUR$', '')\n",
    "    data['Satisfation with employer'].fillna(data['Satisfation with employer'].mode()[0],inplace=True)\n",
    "    data['Yearly Income in addition to Salary (e.g. Rental Income)']=data['Yearly Income in addition to Salary (e.g. Rental Income)'].astype(float)\n",
    "    print(\"\\nCleanup finished...\")    \n",
    "    return data\n",
    "\n",
    "def create_cat_con(df,cats,cons,normalize=True):\n",
    "    for i,cat in enumerate(cats):\n",
    "        vc = df[cat].value_counts(dropna=False, normalize=normalize).to_dict()\n",
    "        nm = cat + '_FE_FULL'\n",
    "        df[nm] = df[cat].map(vc)\n",
    "        df[nm] = df[nm].astype('float32')\n",
    "        for j,con in enumerate(cons):\n",
    "#             print(\"cat %s con %s\"%(cat,con))\n",
    "            new_col = cat +'_'+ con\n",
    "            #print('timeblock frequency encoding:', new_col)\n",
    "            df[new_col] = df[cat].astype(str)+'_'+df[con].astype(str)\n",
    "            temp_df = df[new_col]\n",
    "            fq_encode = temp_df.value_counts(normalize=True).to_dict()\n",
    "            df[new_col] = df[new_col].map(fq_encode)\n",
    "            df[new_col] = df[new_col]/df[cat+'_FE_FULL']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Data/tcd-ml-1920-group-income-train.csv\", low_memory=False)\n",
    "\n",
    "test = pd.read_csv(\"Data/tcd-ml-1920-group-income-test.csv\", low_memory=False)\n",
    "\n",
    "train.drop_duplicates(inplace=True)\n",
    "test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning Cleanup...\n",
      "\n",
      "Cleanup finished...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfill_col_dict = {'Year of Record': 1999.0,\\n 'Gender':'female',\\n 'Age': 15,\\n 'Profession': 'principal administrative associate',\\n 'University Degree': 0,\\n 'Hair Color': 'Black'}\\nfor col in fill_col_dict.keys():\\n    data[col] = data[col].fillna(fill_col_dict[col])\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train,test],ignore_index=True)\n",
    "data = cleanUp(data)\n",
    "\"\"\"\n",
    "fill_col_dict = {'Year of Record': 1999.0,\n",
    " 'Gender':'female',\n",
    " 'Age': 15,\n",
    " 'Profession': 'principal administrative associate',\n",
    " 'University Degree': 0,\n",
    " 'Hair Color': 'Black'}\n",
    "for col in fill_col_dict.keys():\n",
    "    data[col] = data[col].fillna(fill_col_dict[col])\n",
    "\"\"\"    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1361147 entries, 0 to 1361146\n",
      "Data columns (total 17 columns):\n",
      "Instance                                                    1361147 non-null int64\n",
      "Year of Record                                              1361147 non-null float64\n",
      "Housing Situation                                           1361147 non-null object\n",
      "Crime Level in the City of Employement                      1361147 non-null int64\n",
      "Work Experience in Current Job [years]                      1361147 non-null float64\n",
      "Satisfation with employer                                   1361147 non-null object\n",
      "Gender                                                      1361147 non-null object\n",
      "Age                                                         1361147 non-null int64\n",
      "Country                                                     1361147 non-null object\n",
      "Size of City                                                1361147 non-null int64\n",
      "Profession                                                  1361147 non-null object\n",
      "University Degree                                           1361147 non-null object\n",
      "Wears Glasses                                               1361147 non-null int64\n",
      "Hair Color                                                  1361147 non-null object\n",
      "Body Height [cm]                                            1361147 non-null int64\n",
      "Yearly Income in addition to Salary (e.g. Rental Income)    1361147 non-null float64\n",
      "Total Yearly Income [EUR]                                   991709 non-null float64\n",
      "dtypes: float64(4), int64(6), object(7)\n",
      "memory usage: 176.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = ['Year of Record', 'Gender', 'Country',\n",
    "        'Profession', 'University Degree','Wears Glasses',\n",
    "        'Hair Color','Age','Housing Situation','Satisfation with employer']\n",
    "#,'Housing Situation','Satisfation with employer']\n",
    "cons = ['Size of City','Body Height [cm]','Crime Level in the City of Employement','Work Experience in Current Job [years]'\n",
    "        ,'Yearly Income in addition to Salary (e.g. Rental Income)']\n",
    "#,'Crime Level in the City of Employement','Work Experience in Current Job [years]','Yearly Income in addition to Salary (e.g. Rental Income)']\n",
    "\n",
    "data = create_cat_con(data,cats,cons)\n",
    "\n",
    "for col in train.dtypes[train.dtypes == 'object'].index.tolist():\n",
    "    feat_le = LabelEncoder()\n",
    "    feat_le.fit(data[col].unique().astype(str))\n",
    "    data[col] = feat_le.transform(data[col].astype(str))\n",
    "\n",
    "del_col = set(['Total Yearly Income [EUR]','Instance'])\n",
    "features_col =  list(set(data) - del_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[:991709].to_csv('imputedtrain.csv',index=False)\n",
    "#data[991709:].to_csv('imputertest.csv',index=False)\n",
    "X_train,X_test = data[features_col].iloc[:991709],data[features_col].iloc[991709:]\n",
    "Y_train = data['Total Yearly Income [EUR]'].iloc[:991709]\n",
    "X_test_id = data['Instance'].iloc[991709:]\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_train,Y_train,test_size=0.2,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's l1: 35261.6\tvalid_1's l1: 35267.8\n",
      "[2000]\ttraining's l1: 22524.7\tvalid_1's l1: 22534.3\n",
      "[3000]\ttraining's l1: 17851.3\tvalid_1's l1: 17872.7\n",
      "[4000]\ttraining's l1: 15521.7\tvalid_1's l1: 15577.6\n",
      "[5000]\ttraining's l1: 14172.5\tvalid_1's l1: 14250.3\n",
      "[6000]\ttraining's l1: 13428.7\tvalid_1's l1: 13524.4\n",
      "[7000]\ttraining's l1: 12968.9\tvalid_1's l1: 13082.3\n",
      "[8000]\ttraining's l1: 12622.3\tvalid_1's l1: 12753.9\n",
      "[9000]\ttraining's l1: 12347.4\tvalid_1's l1: 12493.9\n",
      "[10000]\ttraining's l1: 12144.6\tvalid_1's l1: 12305.7\n",
      "[11000]\ttraining's l1: 11949\tvalid_1's l1: 12120.8\n",
      "[12000]\ttraining's l1: 11815.4\tvalid_1's l1: 11999.6\n",
      "[13000]\ttraining's l1: 11707.9\tvalid_1's l1: 11904.1\n",
      "[14000]\ttraining's l1: 11614.6\tvalid_1's l1: 11821.9\n",
      "[15000]\ttraining's l1: 11521.6\tvalid_1's l1: 11740.3\n",
      "[16000]\ttraining's l1: 11449.7\tvalid_1's l1: 11679.6\n",
      "[17000]\ttraining's l1: 11387.5\tvalid_1's l1: 11629.2\n",
      "[18000]\ttraining's l1: 11329.7\tvalid_1's l1: 11583\n",
      "[19000]\ttraining's l1: 11275.6\tvalid_1's l1: 11540.4\n",
      "[20000]\ttraining's l1: 11229.4\tvalid_1's l1: 11506.5\n",
      "[21000]\ttraining's l1: 11185.9\tvalid_1's l1: 11475.4\n",
      "[22000]\ttraining's l1: 11142.7\tvalid_1's l1: 11444.7\n",
      "[23000]\ttraining's l1: 11099.7\tvalid_1's l1: 11413.2\n",
      "[24000]\ttraining's l1: 11060.7\tvalid_1's l1: 11385.5\n",
      "[25000]\ttraining's l1: 11021.6\tvalid_1's l1: 11357.5\n",
      "[26000]\ttraining's l1: 10982.1\tvalid_1's l1: 11328.9\n",
      "[27000]\ttraining's l1: 10949.1\tvalid_1's l1: 11306.8\n",
      "[28000]\ttraining's l1: 10916.2\tvalid_1's l1: 11284.6\n",
      "[29000]\ttraining's l1: 10886.2\tvalid_1's l1: 11265\n",
      "[30000]\ttraining's l1: 10851.6\tvalid_1's l1: 11240.5\n",
      "[31000]\ttraining's l1: 10820.4\tvalid_1's l1: 11219.1\n",
      "[32000]\ttraining's l1: 10791.3\tvalid_1's l1: 11200.3\n",
      "[33000]\ttraining's l1: 10762\tvalid_1's l1: 11181.4\n",
      "[34000]\ttraining's l1: 10722.7\tvalid_1's l1: 11151.5\n",
      "[35000]\ttraining's l1: 10685\tvalid_1's l1: 11122.9\n",
      "[36000]\ttraining's l1: 10653\tvalid_1's l1: 11100.5\n",
      "[37000]\ttraining's l1: 10623.8\tvalid_1's l1: 11081\n",
      "[38000]\ttraining's l1: 10597.7\tvalid_1's l1: 11064.5\n",
      "[39000]\ttraining's l1: 10571.4\tvalid_1's l1: 11047.4\n",
      "[40000]\ttraining's l1: 10546.6\tvalid_1's l1: 11032\n",
      "[41000]\ttraining's l1: 10519.7\tvalid_1's l1: 11015.2\n",
      "[42000]\ttraining's l1: 10494\tvalid_1's l1: 10999.2\n",
      "[43000]\ttraining's l1: 10470.7\tvalid_1's l1: 10984.5\n",
      "[44000]\ttraining's l1: 10445.4\tvalid_1's l1: 10968.1\n",
      "[45000]\ttraining's l1: 10421.5\tvalid_1's l1: 10952.9\n",
      "[46000]\ttraining's l1: 10398.9\tvalid_1's l1: 10939.1\n",
      "[47000]\ttraining's l1: 10369.2\tvalid_1's l1: 10917.8\n",
      "[48000]\ttraining's l1: 10336.5\tvalid_1's l1: 10890.6\n",
      "[49000]\ttraining's l1: 10313.3\tvalid_1's l1: 10875.7\n",
      "[50000]\ttraining's l1: 10293.9\tvalid_1's l1: 10865.7\n",
      "[51000]\ttraining's l1: 10273\tvalid_1's l1: 10854.3\n",
      "[52000]\ttraining's l1: 10252.9\tvalid_1's l1: 10843.5\n",
      "[53000]\ttraining's l1: 10234.1\tvalid_1's l1: 10834.2\n",
      "[54000]\ttraining's l1: 10214.6\tvalid_1's l1: 10823.8\n",
      "[55000]\ttraining's l1: 10196.2\tvalid_1's l1: 10814.8\n",
      "[56000]\ttraining's l1: 10177.6\tvalid_1's l1: 10805.3\n",
      "[57000]\ttraining's l1: 10159.8\tvalid_1's l1: 10796.7\n",
      "[58000]\ttraining's l1: 10143.6\tvalid_1's l1: 10789.6\n",
      "[59000]\ttraining's l1: 10124.1\tvalid_1's l1: 10778.9\n",
      "[60000]\ttraining's l1: 10105.8\tvalid_1's l1: 10769.3\n",
      "[61000]\ttraining's l1: 10089.5\tvalid_1's l1: 10762.5\n",
      "[62000]\ttraining's l1: 10073.1\tvalid_1's l1: 10755\n",
      "[63000]\ttraining's l1: 10056.8\tvalid_1's l1: 10747.4\n",
      "[64000]\ttraining's l1: 10040.2\tvalid_1's l1: 10740.1\n",
      "[65000]\ttraining's l1: 10024.9\tvalid_1's l1: 10734.3\n",
      "[66000]\ttraining's l1: 10009.5\tvalid_1's l1: 10727.9\n",
      "[67000]\ttraining's l1: 9994.77\tvalid_1's l1: 10721.6\n",
      "[68000]\ttraining's l1: 9980.11\tvalid_1's l1: 10715\n",
      "[69000]\ttraining's l1: 9964.46\tvalid_1's l1: 10707.6\n",
      "[70000]\ttraining's l1: 9949.8\tvalid_1's l1: 10701.2\n",
      "[71000]\ttraining's l1: 9935.43\tvalid_1's l1: 10694.9\n",
      "[72000]\ttraining's l1: 9920.16\tvalid_1's l1: 10687.6\n",
      "[73000]\ttraining's l1: 9905.46\tvalid_1's l1: 10681.3\n",
      "[74000]\ttraining's l1: 9892.52\tvalid_1's l1: 10677\n",
      "[75000]\ttraining's l1: 9878.21\tvalid_1's l1: 10671.7\n",
      "[76000]\ttraining's l1: 9863.45\tvalid_1's l1: 10666\n",
      "[77000]\ttraining's l1: 9846.22\tvalid_1's l1: 10657.5\n",
      "[78000]\ttraining's l1: 9831.63\tvalid_1's l1: 10651.4\n",
      "[79000]\ttraining's l1: 9818.87\tvalid_1's l1: 10647.4\n",
      "[80000]\ttraining's l1: 9805.78\tvalid_1's l1: 10643.3\n",
      "[81000]\ttraining's l1: 9793.01\tvalid_1's l1: 10639.3\n",
      "[82000]\ttraining's l1: 9780.66\tvalid_1's l1: 10636.1\n",
      "[83000]\ttraining's l1: 9768.51\tvalid_1's l1: 10633.1\n",
      "[84000]\ttraining's l1: 9756.25\tvalid_1's l1: 10629.8\n",
      "[85000]\ttraining's l1: 9744.05\tvalid_1's l1: 10626.2\n",
      "[86000]\ttraining's l1: 9731.75\tvalid_1's l1: 10621.9\n",
      "[87000]\ttraining's l1: 9719.61\tvalid_1's l1: 10618.6\n",
      "[88000]\ttraining's l1: 9706.94\tvalid_1's l1: 10615.1\n",
      "[89000]\ttraining's l1: 9692.68\tvalid_1's l1: 10609.8\n",
      "[90000]\ttraining's l1: 9680.15\tvalid_1's l1: 10605.8\n",
      "[91000]\ttraining's l1: 9667.32\tvalid_1's l1: 10601.8\n",
      "[92000]\ttraining's l1: 9655.01\tvalid_1's l1: 10598.4\n",
      "[93000]\ttraining's l1: 9641.27\tvalid_1's l1: 10593.7\n",
      "[94000]\ttraining's l1: 9628.16\tvalid_1's l1: 10589.4\n",
      "[95000]\ttraining's l1: 9615.77\tvalid_1's l1: 10585.6\n",
      "[96000]\ttraining's l1: 9603.93\tvalid_1's l1: 10582.3\n",
      "[97000]\ttraining's l1: 9591.94\tvalid_1's l1: 10578.7\n",
      "[98000]\ttraining's l1: 9580.32\tvalid_1's l1: 10575.5\n",
      "[99000]\ttraining's l1: 9569.34\tvalid_1's l1: 10572.8\n",
      "[100000]\ttraining's l1: 9557.83\tvalid_1's l1: 10569.5\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100000]\ttraining's l1: 9557.83\tvalid_1's l1: 10569.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "          'max_depth': 20,\n",
    "          'learning_rate': 0.001,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "             \"device\":'gpu',\n",
    "    \"gpuusedp\":\"true\"\n",
    "         }\n",
    "trn_data = lgb.Dataset(x_train, label=y_train)\n",
    "val_data = lgb.Dataset(x_val, label=y_val)\n",
    "# test_data = lgb.Dataset(X_test)\n",
    "clf = lgb.train(params, trn_data, 100000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=500)\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10569.476636625492"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "pre_test_lgb = clf.predict(x_val)\n",
    "\n",
    "val_mae = mean_absolute_error(y_val,pre_test_lgb)\n",
    "val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71122        530.76\n",
      "378543      1866.95\n",
      "139206      2334.03\n",
      "152073      2218.83\n",
      "929019    174818.58\n",
      "56828       2277.67\n",
      "192404      5547.22\n",
      "950993    118301.24\n",
      "551194     89414.48\n",
      "239981      6544.38\n",
      "Name: Total Yearly Income [EUR], dtype: float64\n",
      "               0\n",
      "0    -173.257400\n",
      "1    4122.163544\n",
      "2     863.439286\n",
      "3    1409.336683\n",
      "4  252877.123381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "barWidth=0.25\n",
    "bars1=y_val.iloc[:10]\n",
    "print(bars1)\n",
    "bars2=pd.DataFrame(pre_test_lgb).iloc[:5]\n",
    "print(bars2)\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "#plt.bar(r1, bars1, color='#7f6d5f', width=barWidth, edgecolor='white', label='actual')\n",
    "plt.bar(r2, bars2, color='#557f2d', width=barWidth, edgecolor='white', label='calculated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_test_lgbdf=pd.DataFrame(pre_test_lgb)\n",
    "pre_test_lgbdf.to_csv('resultval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_test_lgb = clf.predict(X_test)\n",
    "\n",
    "sub_df = pd.DataFrame({'Instance':X_test_id,\n",
    "                       'Income':post_test_lgb})\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission1.csv\",index=False)\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = [12, 30, 1, 8, 22]\n",
    "bars2 = [28, 6, 16, 5, 10]\n",
    "bars3 = [29, 3, 24, 25, 17]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='#7f6d5f', width=barWidth, edgecolor='white', label='var1')\n",
    "plt.bar(r2, bars2, color='#557f2d', width=barWidth, edgecolor='white', label='var2')\n",
    "plt.bar(r3, bars3, color='#2d7f5e', width=barWidth, edgecolor='white', label='var3')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('group', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['A', 'B', 'C', 'D', 'E'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
